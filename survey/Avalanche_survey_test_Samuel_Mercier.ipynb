{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## *Note: before you run this notebook, make sure to upload the coded_responses.csv file!*"
      ],
      "metadata": {
        "id": "8jr7Y8YFT795"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the libraries\n",
        "Let's install and import all the libraries we will use in this notebook. It's good practice to keep them at the top."
      ],
      "metadata": {
        "id": "uR693tlrylFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install top2vec[sentence_encoders]\n",
        "!pip install tensorflow_hub tensorflow_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctiAL3Imy8IU",
        "outputId": "290879e2-d01a-422f-8bb1-aedc6c521ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting top2vec[sentence_encoders]\n",
            "  Downloading top2vec-1.0.27-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.21.6)\n",
            "Collecting hdbscan>=0.8.27\n",
            "  Downloading hdbscan-0.8.29.tar.gz (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 35.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.8.2.2)\n",
            "Collecting gensim>=4.0.0\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting umap-learn>=0.5.1\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.12.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (2.9.2)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 9.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec[sentence_encoders]) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->top2vec[sentence_encoders]) (1.7.3)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.2.0)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (0.29.32)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->hdbscan>=0.8.27->top2vec[sentence_encoders]) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.56.4)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (4.64.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->top2vec[sentence_encoders]) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.9.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.27.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.1.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.50.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.12)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->top2vec[sentence_encoders]) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->top2vec[sentence_encoders]) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (2.14.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->top2vec[sentence_encoders]) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow->top2vec[sentence_encoders]) (3.0.9)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 6.6 kB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 69.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow\n",
            "  Downloading tensorflow-2.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 28 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 17 kB/s \n",
            "\u001b[?25hCollecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 36.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec[sentence_encoders]) (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec[sentence_encoders]) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud->top2vec[sentence_encoders]) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->wordcloud->top2vec[sentence_encoders]) (0.11.0)\n",
            "Building wheels for collected packages: hdbscan, umap-learn, pynndescent\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.29-cp37-cp37m-linux_x86_64.whl size=2340670 sha256=3e6b63efc7c9ba2d5e50bfb69f4622687a9696814e5e2aea00288b0bb2d6bba3\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/78/2e/03ee191669a772e9653260aa3bd53e0b1a768751a9676e8c82\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=f4b75088b9c3722cb5f47390f7e1ad409568e8066914e4adda87c6626138aac7\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/52/a5/1fd9e3e76a7ab34f134c07469cd6f16e27ef3a37aeff1fe821\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55513 sha256=c849fbfd4adca7208111a40f4eb0478d3e03f38f7d1c35ab743f32c2a58b463c\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/bc/eb/974072a56a7082a302f8b4be1ad6d21bf5019235c2eff65928\n",
            "Successfully built hdbscan umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn, hdbscan, gensim, top2vec, tensorflow-text\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0 hdbscan-0.8.29 pynndescent-0.5.8 tensorflow-text-2.9.0 top2vec-1.0.27 umap-learn-0.5.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (3.19.6)\n",
            "Requirement already satisfied: tensorflow<2.10,>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.9.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (4.1.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.12)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.50.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (14.0.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (0.27.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (2.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (2.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.10,>=2.9.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.10,>=2.9.0->tensorflow_text) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "from top2vec import Top2Vec"
      ],
      "metadata": {
        "id": "MxaB2sF1ynxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read the data\n",
        "First off, let's read the data. Make sure you have uploaded the coded_responses.csv file. We'll use Pandas and store the data in a \"df\" dataframe."
      ],
      "metadata": {
        "id": "Kkt3eUiJySjI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4TBikJLyL1W"
      },
      "outputs": [],
      "source": [
        "# Make sure you have uploaded your coded_responses.csv file :)\n",
        "df = pd.read_csv('coded_responses.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validate the data\n",
        "It's good practice to validate the data. In our case, let's just make sure we have the right number of lines (663) and visualize a few rows."
      ],
      "metadata": {
        "id": "jKLgkayYzREV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(df)==663, \"expected a dataframe with 663 responses\""
      ],
      "metadata": {
        "id": "cvz29C_ezc3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "IAPVGS050AEv",
        "outputId": "6482d04c-9d40-4040-8ac1-8f9453503157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  question  respondent_id  \\\n",
              "0  Why are you cancelling?        1779533   \n",
              "1  Why are you cancelling?        1779397   \n",
              "2  Why are you cancelling?        1779811   \n",
              "3  Why are you cancelling?        1779968   \n",
              "4  Why are you cancelling?        1779967   \n",
              "\n",
              "                                          response  \\\n",
              "0                         seen what I like already   \n",
              "1  You keep canceling really good, popular series!   \n",
              "2                    Getting through cell provider   \n",
              "3                                      Budget cuts   \n",
              "4                       Cannot have multiple users   \n",
              "\n",
              "                                       theme  \n",
              "0                                        NaN  \n",
              "1                                        NaN  \n",
              "2                                        NaN  \n",
              "3  Reducing expenses / financial constraints  \n",
              "4             Object to sharing restrictions  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acd56ae9-e6b8-473a-91eb-58c8d3c2cbc0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>respondent_id</th>\n",
              "      <th>response</th>\n",
              "      <th>theme</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779533</td>\n",
              "      <td>seen what I like already</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779397</td>\n",
              "      <td>You keep canceling really good, popular series!</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779811</td>\n",
              "      <td>Getting through cell provider</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779968</td>\n",
              "      <td>Budget cuts</td>\n",
              "      <td>Reducing expenses / financial constraints</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779967</td>\n",
              "      <td>Cannot have multiple users</td>\n",
              "      <td>Object to sharing restrictions</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acd56ae9-e6b8-473a-91eb-58c8d3c2cbc0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acd56ae9-e6b8-473a-91eb-58c8d3c2cbc0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acd56ae9-e6b8-473a-91eb-58c8d3c2cbc0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also see if some respondents have many responses."
      ],
      "metadata": {
        "id": "s_NmwlpR0EEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.respondent_id.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO3GSe1_0JhJ",
        "outputId": "31dd7505-9530-42fe-bbd0-4eb7ce53e383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1779433    4\n",
              "1779457    3\n",
              "1779410    3\n",
              "1779452    3\n",
              "1779828    3\n",
              "          ..\n",
              "1779694    1\n",
              "1779693    1\n",
              "1779692    1\n",
              "1779691    1\n",
              "1779369    1\n",
              "Name: respondent_id, Length: 600, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that a few respondents have many responses, which may or may not adequate depending on the survey. Let's investigate the responses of respondent id 1779433, to see if the responses are duplicate"
      ],
      "metadata": {
        "id": "79lMs1y_0VMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.respondent_id==1779433]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "qyLl_vjW0QTX",
        "outputId": "7262e026-d28b-4b3a-8280-265ee1c743ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    question  respondent_id  \\\n",
              "458  Why are you cancelling?        1779433   \n",
              "459  Why are you cancelling?        1779433   \n",
              "460  Why are you cancelling?        1779433   \n",
              "461  Why are you cancelling?        1779433   \n",
              "\n",
              "                                              response  \\\n",
              "458  Way to many price hikes over the past few year...   \n",
              "459  Way to many price hikes over the past few year...   \n",
              "460  Way to many price hikes over the past few year...   \n",
              "461  Way to many price hikes over the past few year...   \n",
              "\n",
              "                                               theme  \n",
              "458                     Object to additional charges  \n",
              "459                   Object to sharing restrictions  \n",
              "460  Corporate greed / taking advantage of customers  \n",
              "461                   Constant price rise / increase  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-374a44d1-07ff-495f-9891-5b2bcc9e23f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>respondent_id</th>\n",
              "      <th>response</th>\n",
              "      <th>theme</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779433</td>\n",
              "      <td>Way to many price hikes over the past few year...</td>\n",
              "      <td>Object to additional charges</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779433</td>\n",
              "      <td>Way to many price hikes over the past few year...</td>\n",
              "      <td>Object to sharing restrictions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779433</td>\n",
              "      <td>Way to many price hikes over the past few year...</td>\n",
              "      <td>Corporate greed / taking advantage of customers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779433</td>\n",
              "      <td>Way to many price hikes over the past few year...</td>\n",
              "      <td>Constant price rise / increase</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-374a44d1-07ff-495f-9891-5b2bcc9e23f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-374a44d1-07ff-495f-9891-5b2bcc9e23f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-374a44d1-07ff-495f-9891-5b2bcc9e23f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWKpmMZz1ToI",
        "outputId": "7c51b64b-322c-40dd-b555-065591fc852e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "question         object\n",
              "respondent_id     int64\n",
              "response         object\n",
              "theme            object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that duplication is caused by the presence of multiple themes. To avoid overweighting these responses in the following analyses, let's combine all themes in a single array."
      ],
      "metadata": {
        "id": "cykbR5rY0yPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.groupby(['question', 'respondent_id', 'response'])['theme'].apply(list).reset_index()"
      ],
      "metadata": {
        "id": "t5Eq-D-O0PW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's validate that we now have a single row for our user 1779433"
      ],
      "metadata": {
        "id": "VjVKGeHg1kjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.respondent_id==1779433]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "Tx9PlAje1dxG",
        "outputId": "f8a7deee-a336-4752-f15d-e495a21f3cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   question  respondent_id  \\\n",
              "64  Why are you cancelling?        1779433   \n",
              "\n",
              "                                             response  \\\n",
              "64  Way to many price hikes over the past few year...   \n",
              "\n",
              "                                                theme  \n",
              "64  [Object to additional charges, Object to shari...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfcaff02-5428-4271-8bad-4a6cc33735ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>respondent_id</th>\n",
              "      <th>response</th>\n",
              "      <th>theme</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779433</td>\n",
              "      <td>Way to many price hikes over the past few year...</td>\n",
              "      <td>[Object to additional charges, Object to shari...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfcaff02-5428-4271-8bad-4a6cc33735ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bfcaff02-5428-4271-8bad-4a6cc33735ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bfcaff02-5428-4271-8bad-4a6cc33735ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess the data\n",
        "Basic NLP preprocessing include lower casing everything and removing the stop words (we do that for most NLP algorithms).\n"
      ],
      "metadata": {
        "id": "tp6KrHjwzwpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#lowercasing\n",
        "df['response_preprocessed'] = df['response'].str.lower()"
      ],
      "metadata": {
        "id": "5D8aLlKX1_Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stop words\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "df['response_preprocessed'] = df['response_preprocessed'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA0vXWFL2Z47",
        "outputId": "53e13e2d-ddb1-4e51-a87b-0bd92734d040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize the impact of preprocessing. We can see that removing stop words does a good cleanup and reduces the length of the responses. However, it could affect meaning in a few cases. For instance, the preprocessed responsed \"rates higher others thing\" loses meaning with respect to the initial response \"Your rates are higher than others who do the same thing\". As such, removing stop words may or may not be relevant depending for the analysis. This is something that should be looked at more thoroughly by investigating the results with and without this preprocessing step."
      ],
      "metadata": {
        "id": "MVX2ZPoD3iLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "a7o688Vg29zT",
        "outputId": "3a1e97db-5327-4875-9ce2-1fcc481220a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  question  respondent_id  \\\n",
              "0  Why are you cancelling?        1779369   \n",
              "1  Why are you cancelling?        1779370   \n",
              "2  Why are you cancelling?        1779371   \n",
              "3  Why are you cancelling?        1779372   \n",
              "4  Why are you cancelling?        1779373   \n",
              "\n",
              "                                            response  \\\n",
              "0                       Your stupid price hike again   \n",
              "1  Your rates are higher than others who do the s...   \n",
              "2  Your profits are up and you're *raising* my pr...   \n",
              "3  Your pricing is terrible. You keep increasing ...   \n",
              "4  Your price is just not worth keeping anymore e...   \n",
              "\n",
              "                                               theme  \\\n",
              "0                   [Constant price rise / increase]   \n",
              "1                [Prefer competition, Too expensive]   \n",
              "2                   [Constant price rise / increase]   \n",
              "3  [Object to sharing restrictions, Corporate gre...   \n",
              "4                                    [Too expensive]   \n",
              "\n",
              "                               response_preprocessed  \n",
              "0                                  stupid price hike  \n",
              "1                          rates higher others thing  \n",
              "2               profits *raising* price? kidding me?  \n",
              "3  pricing terrible. keep increasing prices addit...  \n",
              "4  price worth keeping anymore especially pop cur...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aefc141d-44c4-4f0e-a242-440dacf1c865\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>respondent_id</th>\n",
              "      <th>response</th>\n",
              "      <th>theme</th>\n",
              "      <th>response_preprocessed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779369</td>\n",
              "      <td>Your stupid price hike again</td>\n",
              "      <td>[Constant price rise / increase]</td>\n",
              "      <td>stupid price hike</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779370</td>\n",
              "      <td>Your rates are higher than others who do the s...</td>\n",
              "      <td>[Prefer competition, Too expensive]</td>\n",
              "      <td>rates higher others thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779371</td>\n",
              "      <td>Your profits are up and you're *raising* my pr...</td>\n",
              "      <td>[Constant price rise / increase]</td>\n",
              "      <td>profits *raising* price? kidding me?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779372</td>\n",
              "      <td>Your pricing is terrible. You keep increasing ...</td>\n",
              "      <td>[Object to sharing restrictions, Corporate gre...</td>\n",
              "      <td>pricing terrible. keep increasing prices addit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Why are you cancelling?</td>\n",
              "      <td>1779373</td>\n",
              "      <td>Your price is just not worth keeping anymore e...</td>\n",
              "      <td>[Too expensive]</td>\n",
              "      <td>price worth keeping anymore especially pop cur...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aefc141d-44c4-4f0e-a242-440dacf1c865')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aefc141d-44c4-4f0e-a242-440dacf1c865 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aefc141d-44c4-4f0e-a242-440dacf1c865');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we could do further preprocessing, like lemmatization or stemming. However, considering the small size of the dataset (few responses and a small corpus of words), I would avoid these preprocessing steps to begin with."
      ],
      "metadata": {
        "id": "jO5PiDQk4b7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: generate actionable information from the responses"
      ],
      "metadata": {
        "id": "RoV7kRnq4GBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the dataframe has been preprocessed, let's try to identify relevant information from the responses. My proposal would be to group the responses into a a smaller, manageable number of groups that we can then easily analyse. This is called clustering. For text, I like to use top2vec library. It is simple to use and will do the two steps of embedding (mapping our responses to a feature vector space) and clustering (finding groups of similar responses) for us. "
      ],
      "metadata": {
        "id": "J6_W7rup4V-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all responses\n",
        "# responses = df['response'].values\n",
        "responses = df['response_preprocessed'].values"
      ],
      "metadata": {
        "id": "ae0yJnAR5tka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use a number of different embedding models. Let's use a basic universal-sentence-encoder.\n",
        "model = Top2Vec(responses, embedding_model='universal-sentence-encoder')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgVo4Oy24FKI",
        "outputId": "a41d74cc-8cbb-485a-ba33-2d8c8f9e4c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-11-29 03:07:06,176 - top2vec - INFO - Pre-processing documents for training\n",
            "INFO:top2vec:Pre-processing documents for training\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "2022-11-29 03:07:06,204 - top2vec - INFO - Downloading universal-sentence-encoder model\n",
            "INFO:top2vec:Downloading universal-sentence-encoder model\n",
            "2022-11-29 03:07:11,113 - top2vec - INFO - Creating joint document/word embedding\n",
            "INFO:top2vec:Creating joint document/word embedding\n",
            "2022-11-29 03:07:11,564 - top2vec - INFO - Creating lower dimension embedding of documents\n",
            "INFO:top2vec:Creating lower dimension embedding of documents\n",
            "2022-11-29 03:07:16,694 - top2vec - INFO - Finding dense areas of documents\n",
            "INFO:top2vec:Finding dense areas of documents\n",
            "2022-11-29 03:07:16,717 - top2vec - INFO - Finding topics\n",
            "INFO:top2vec:Finding topics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that top2vec algorithm found eighth different groups of similar responses"
      ],
      "metadata": {
        "id": "UrX_0Gpg9Ict"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note that top2vec library uses a dimensionality reduction technique (UMAP) that is not deterministic. As such, if you run the notebook again, it is possible that you will find a slightly different (ex: 7 or 9) number of groups!*"
      ],
      "metadata": {
        "id": "12TJndqQVmjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_num_topics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5gDa6Vn6PX-",
        "outputId": "46906896-fb87-4d35-e923-842d2b0720c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can assume that each group of similar responses describe a similar topic. Let's analyse those, by printing a few responses and looking at the most frequent words."
      ],
      "metadata": {
        "id": "d98W2lLO9Z1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's write a few helper functions\n",
        "def response_examples(topic_number: int):\n",
        "  documents, document_scores, document_ids = model.search_documents_by_topic(topic_num=topic_number,\n",
        "                                                                             num_docs=20)\n",
        "  return documents\n",
        "\n",
        "def get_size_of_cluster(topic_number: int):\n",
        "  return model.get_topic_sizes()[0][topic_number]\n",
        "\n",
        "def most_frequent_words(topic_number: int):\n",
        "  documents, _, _ = model.search_documents_by_topic(topic_num=topic_number,\n",
        "                                                    num_docs=get_size_of_cluster(topic_number))\n",
        "  words = [i.split() for i in documents] # Split sentences into words\n",
        "  words = [i for sublist in words for i in sublist] # Flatten the list\n",
        "  word_count = Counter(words).most_common(10) # Find most common words\n",
        "  return word_count"
      ],
      "metadata": {
        "id": "sBDR5hsJ9m9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Investigating topic 1. It's the biggest (about one third of the responses), and we can see it is clearly related to price increases."
      ],
      "metadata": {
        "id": "G7JqwIZKABZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First topic\n",
        "topic_number = 0\n",
        "print(f\"\"\"\n",
        "INVESTIGATING TOPIC {topic_number}.\n",
        "\n",
        "SIZE OF THE TOPIC: {get_size_of_cluster(topic_number)}\n",
        "\n",
        "EXAMPLE OF RESPONSES: {response_examples(topic_number)}\n",
        "\n",
        "MOST FREQUENT WORDS: {most_frequent_words(topic_number)}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXxiR3T9-9gK",
        "outputId": "ef9d593c-cbdd-4ab2-8d81-b8e8b0205afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INVESTIGATING TOPIC 0.\n",
            "\n",
            "SIZE OF THE TOPIC: 190\n",
            "\n",
            "EXAMPLE OF RESPONSES: ['keep increasing prices.' 'price keeps increasing'\n",
            " 'price keeps increasing' 'price increase much!!' 'price increase absurd'\n",
            " 'price increasing' 'price increase worth' 'price increases'\n",
            " 'price increase? __' 'pay price increase' 'continual price increases'\n",
            " 'continual price increases' 'keep raising prices' 'sick price increases'\n",
            " 'price increase cant afford anymore' 'worth price increase'\n",
            " 'worth price increase.' 'price increases often.' 'stop raising prices'\n",
            " 'stop raising prices!']\n",
            "\n",
            "MOST FREQUENT WORDS: [('price', 113), ('keep', 30), ('increase', 30), ('prices', 25), ('increases', 24), ('raising', 23), ('many', 12), ('worth', 11), ('increasing', 10), ('pay', 9)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second most important topic is related to having access to multiple subscriptions."
      ],
      "metadata": {
        "id": "4i2OhhGtAcDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# second topic\n",
        "topic_number = 1\n",
        "print(f\"\"\"\n",
        "INVESTIGATING TOPIC {topic_number}.\n",
        "\n",
        "SIZE OF THE TOPIC: {get_size_of_cluster(topic_number)}\n",
        "\n",
        "EXAMPLE OF RESPONSES: {response_examples(topic_number)}\n",
        "\n",
        "MOST FREQUENT WORDS: {most_frequent_words(topic_number)}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiSgCPPgANfW",
        "outputId": "ba80c15b-90a1-4f78-9d48-5d18986092de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INVESTIGATING TOPIC 1.\n",
            "\n",
            "SIZE OF THE TOPIC: 110\n",
            "\n",
            "EXAMPLE OF RESPONSES: ['multiple subscriptions' 'multiple subscriptions'\n",
            " 'multiple subscriptions' 'spouse subscription' 'fianc�e subscription'\n",
            " 'different subscription' '3 subscriptions 1 household. needed 1'\n",
            " 'using subscription' 'multiple subscriptions house' '2 subscriptions'\n",
            " '2 subscriptions need 1' 'multiple subscriptions. unneeded.'\n",
            " '2 subscriptions set up.' 'two subscriptions'\n",
            " 'wife subscription don�t need 2 subscriptions.' 'husband subscription'\n",
            " 'husband subscription' 'changing subscription' 'another subscription'\n",
            " 'opening different subscriptions']\n",
            "\n",
            "MOST FREQUENT WORDS: [('subscription', 55), ('subscriptions', 23), ('need', 12), ('using', 9), ('two', 7), ('sharing', 7), ('hacked', 7), ('multiple', 6), ('different', 6), ('husband', 6)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The third topic is related to financial considerations (expensive, cannot afford)."
      ],
      "metadata": {
        "id": "mrIpv_KPAjy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# third topic\n",
        "topic_number = 2\n",
        "print(f\"\"\"\n",
        "INVESTIGATING TOPIC {topic_number}.\n",
        "\n",
        "SIZE OF THE TOPIC: {get_size_of_cluster(topic_number)}\n",
        "\n",
        "EXAMPLE OF RESPONSES: {response_examples(topic_number)}\n",
        "\n",
        "MOST FREQUENT WORDS: {most_frequent_words(topic_number)}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Sx6w-Q2AkLB",
        "outputId": "d899df1b-9a42-46ec-be24-169c0bc9d17a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INVESTIGATING TOPIC 2.\n",
            "\n",
            "SIZE OF THE TOPIC: 96\n",
            "\n",
            "EXAMPLE OF RESPONSES: ['cost way tooo much' 'cost going much' \"can't afford right now.\"\n",
            " 'never use & expensive' \"can't afford time.\" \"can't afford right\"\n",
            " \"can't afford right\" 'can�t afford right' 'can�t afford' 'can�t afford'\n",
            " 'cost keeps going' 'cannot afford longer' 'enough money get anymore'\n",
            " 'way expensive' 'expensive right now, maybe later' 'cannot afford'\n",
            " 'use enough warrant cost' 'use enough anymore'\n",
            " \"can't afford time start again.\" 'longer worth']\n",
            "\n",
            "MOST FREQUENT WORDS: [('afford', 12), ('expensive', 12), ('need', 12), ('money', 11), ('use', 9), ('right', 8), ('cost', 7), ('much', 7), (\"can't\", 7), ('enough', 6)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fourth topic is related to the idea of taking a break from the suscription."
      ],
      "metadata": {
        "id": "_2NkHqpEA-09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fourth topic\n",
        "topic_number = 3\n",
        "print(f\"\"\"\n",
        "INVESTIGATING TOPIC {topic_number}.\n",
        "\n",
        "SIZE OF THE TOPIC: {get_size_of_cluster(topic_number)}\n",
        "\n",
        "EXAMPLE OF RESPONSES: {response_examples(topic_number)}\n",
        "\n",
        "MOST FREQUENT WORDS: {most_frequent_words(topic_number)}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrFFkwD_AxAp",
        "outputId": "5fc75fe0-ba7a-434b-d3ac-bc034e436fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INVESTIGATING TOPIC 3.\n",
            "\n",
            "SIZE OF THE TOPIC: 63\n",
            "\n",
            "EXAMPLE OF RESPONSES: ['taking break, back' 'taking break back' 'taking break.' 'taking break'\n",
            " 'taking break.' 'taking break' \"i'm broke. i'll back\" 'take break'\n",
            " 'time break' 'repurposing time. back!' 'back' 'back.' 'back'\n",
            " 'taking break summer' 'back week' 'might back. taking break'\n",
            " 'taking break layoff' 'monetary break. come back.' 'return'\n",
            " 'come back may']\n",
            "\n",
            "MOST FREQUENT WORDS: [('back', 14), ('break', 11), ('taking', 10), ('summer', 5), ('months', 5), ('time', 4), ('back.', 4), ('come', 4), ('break.', 3), ('i�ll', 3)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fifth topic is actually quite similar to the third topic. It's also related to financial considerations, but using other wording (budget, spending)."
      ],
      "metadata": {
        "id": "HTIYq3kDBHQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fifth topic\n",
        "topic_number = 4\n",
        "print(f\"\"\"\n",
        "INVESTIGATING TOPIC {topic_number}.\n",
        "\n",
        "SIZE OF THE TOPIC: {get_size_of_cluster(topic_number)}\n",
        "\n",
        "EXAMPLE OF RESPONSES: {response_examples(topic_number)}\n",
        "\n",
        "MOST FREQUENT WORDS: {most_frequent_words(topic_number)}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GsbDpBVBHxI",
        "outputId": "a9631927-b99e-4e00-ffce-9b83c51ca414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INVESTIGATING TOPIC 4.\n",
            "\n",
            "SIZE OF THE TOPIC: 43\n",
            "\n",
            "EXAMPLE OF RESPONSES: ['budget cutbacks' 'need cut expenses' 'need cut expenses'\n",
            " 'need cut expenses' 'cutting spending' 'making budget cut'\n",
            " 'i�m cutting back spending' 'cutting unnecessary expenses' 'budget cuts'\n",
            " 'budget cuts' 'cutting costs' 'looking cut costs.' 'budget anymore'\n",
            " 'budget issues' 'reducing un-needed expenses' 'budget :(' 'budget'\n",
            " 'laid off, reducing expenses' 'budgeting' 'budgeting']\n",
            "\n",
            "MOST FREQUENT WORDS: [('budget', 10), ('cut', 9), ('expenses', 8), ('money', 6), ('need', 5), ('trying', 5), ('cutting', 4), ('spending', 4), ('save', 4), ('back', 3)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The sixth topic could be combined to the previous one. It is related to financial considerations, using directly the word \"finance\""
      ],
      "metadata": {
        "id": "EuJ1aKIgBjKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_number = 5\n",
        "print(f\"\"\"\n",
        "INVESTIGATING TOPIC {topic_number}.\n",
        "\n",
        "SIZE OF THE TOPIC: {get_size_of_cluster(topic_number)}\n",
        "\n",
        "EXAMPLE OF RESPONSES: {response_examples(topic_number)}\n",
        "\n",
        "MOST FREQUENT WORDS: {most_frequent_words(topic_number)}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmc2PPkbBkgy",
        "outputId": "db2dbdd5-efc8-41a4-962d-236fe6a0f0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INVESTIGATING TOPIC 5.\n",
            "\n",
            "SIZE OF THE TOPIC: 42\n",
            "\n",
            "EXAMPLE OF RESPONSES: [\"i'm financial issues.\" 'financial hardship' 'financial hardship'\n",
            " 'financial hardship' 'financial difficulty' 'financial reasons'\n",
            " 'financial' 'finances' 'finances' 'financial situation changed.'\n",
            " 'financial situation changed' 'unemployed financial issues'\n",
            " 'economy hardship' 'financial cut backs' 'health issues' 'health issues'\n",
            " 'personal income problems' 'finance decision' '$ issues.'\n",
            " 'behind finances']\n",
            "\n",
            "MOST FREQUENT WORDS: [('financial', 11), ('hardship', 4), ('issues', 4), ('money', 4), ('finances', 3), ('job', 3), ('issues.', 2), ('situation', 2), ('economy', 2), ('health', 2)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The seventh topic (about 10% of the responses) is related to relocation"
      ],
      "metadata": {
        "id": "hFaGxoK7HVhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_number = 6\n",
        "print(f\"\"\"\n",
        "INVESTIGATING TOPIC {topic_number}.\n",
        "\n",
        "SIZE OF THE TOPIC: {get_size_of_cluster(topic_number)}\n",
        "\n",
        "EXAMPLE OF RESPONSES: {response_examples(topic_number)}\n",
        "\n",
        "MOST FREQUENT WORDS: {most_frequent_words(topic_number)}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF45qqsPF4xH",
        "outputId": "5836f05c-25b5-4cea-fb2c-a462668bf38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INVESTIGATING TOPIC 6.\n",
            "\n",
            "SIZE OF THE TOPIC: 31\n",
            "\n",
            "EXAMPLE OF RESPONSES: ['moving' 'moving' 'moving' 'moving' 'moving away' 'moving country'\n",
            " 'moving country' 'moved' 'moving another country.' 'moved someone'\n",
            " 'moved uk' 'moved family' 'moved us - start'\n",
            " 'moving new location ontario' 'moved someone already'\n",
            " \"i'm moving rejoin get settled.\" 'moving now. thank you.'\n",
            " 'change new country'\n",
            " 'moved different country want changed currency current location'\n",
            " 'moved boyfriend need one']\n",
            "\n",
            "MOST FREQUENT WORDS: [('moving', 11), ('moved', 9), ('country', 4), ('new', 3), ('lost', 3), ('job', 3), ('someone', 2), ('family', 2), ('location', 2), ('using', 2)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final topic is a little more diverse (it happens often with clustering: the minor clusters are a little big less statistically significant). Nevertheless, this cluster is often related to people having passed away."
      ],
      "metadata": {
        "id": "ySYkOAhwHeIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_number = 7\n",
        "print(f\"\"\"\n",
        "INVESTIGATING TOPIC {topic_number}.\n",
        "\n",
        "SIZE OF THE TOPIC: {get_size_of_cluster(topic_number)}\n",
        "\n",
        "EXAMPLE OF RESPONSES: {response_examples(topic_number)}\n",
        "\n",
        "MOST FREQUENT WORDS: {most_frequent_words(topic_number)}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiykLbc9F73k",
        "outputId": "35bebc41-e02f-42d1-b32f-5e14c0c826b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INVESTIGATING TOPIC 7.\n",
            "\n",
            "SIZE OF THE TOPIC: 25\n",
            "\n",
            "EXAMPLE OF RESPONSES: ['person passed away' 'user passed away' 'user passed away'\n",
            " 'subscriber passed away' 'person paying passed away.'\n",
            " 'mom passed away account' 'owner subscription passed away'\n",
            " 'member passed away' 'subscription owner passed away' 'wife passed away'\n",
            " 'parent owning account passed away' 'aunt passed away'\n",
            " 'sharon passed away' 'death account holder' 'death spouse'\n",
            " 'death family.' 'saving $ sharing dad'\n",
            " 'mom live two different places, since want restrict cancel membership.'\n",
            " 'sharing spouse' 'family sharing =[']\n",
            "\n",
            "MOST FREQUENT WORDS: [('passed', 13), ('away', 12), ('account', 3), ('death', 3), ('sharing', 3), ('person', 2), ('user', 2), ('mom', 2), ('owner', 2), ('subscription', 2)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarize, we used an embedding and a clustering algorithm to \"concentrate\" the unstructured responses into a manageable number of groups of similar responses that are easily interpreted. The analysis quickly highlighted that price increase, having multiple subscriptions and financial considerations are some of the most frequent reasons for cancellation mentioned in the survey.\n",
        "\n",
        "This analysis was done fairly quickly and gives, I believe, interesting results. However, if we wanted to fine tune the analysis, we could look at:\n",
        "- different embedding approaches (LDA, TFIDF, other Bert models)\n",
        "- the impact of preprocessing (looking at the list stop words more closely, lemmatization or stemming)\n",
        "- the creation of impactful charts (for example, most frequent words or bigrams)."
      ],
      "metadata": {
        "id": "vtwepFIeQd98"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: data visualization"
      ],
      "metadata": {
        "id": "ZDaNyH7DRgGF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have created a quick data studio to visualize the survey dataset. You can find the data studio here: https://datastudio.google.com/u/1/reporting/0667da9c-80a1-44af-a6bd-fa7c20760715/page/Yq28C "
      ],
      "metadata": {
        "id": "ADdwdre5GA9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The visualization was done very quickly. I decided to use Google Data Studio, because I have ample experience with it, it is simple to use and can be shared without licenses. That said, a dashboard could have been made with any other tool (ex: Tableau) on the market.\n",
        "\n",
        "I wanted the dashboard to:\n",
        "- highlight the importance of the different themes (this is why I used a pie chart)\n",
        "- highlight important/frequent words (the word cloud)\n",
        "- be interactive (you can click on the different charts or filter the responses)\n",
        "- be colorful and intuitive (thus the comments above each chart).\n",
        "\n",
        "With a little more time, I would:\n",
        "- improve the design and the UX. If your dashboard looks good, more people will use it and you will have a greater impact.\n",
        "- use a real data warehouse. The dashboard is simply linked to a Google Sheet, which is good enough considering the size of the dataset. But of course, with bigger surveys, one would need to store the results in another format (ex: bigquery, Redshift) to have a proper and fast dashboard.\n"
      ],
      "metadata": {
        "id": "VZGBF8UiSf8c"
      }
    }
  ]
}